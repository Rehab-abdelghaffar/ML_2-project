{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:29.561308Z",
     "iopub.status.busy": "2025-03-30T08:15:29.561032Z",
     "iopub.status.idle": "2025-03-30T08:15:38.823816Z",
     "shell.execute_reply": "2025-03-30T08:15:38.822897Z",
     "shell.execute_reply.started": "2025-03-30T08:15:29.561278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:38.827706Z",
     "iopub.status.busy": "2025-03-30T08:15:38.827490Z",
     "iopub.status.idle": "2025-03-30T08:15:38.832333Z",
     "shell.execute_reply": "2025-03-30T08:15:38.831397Z",
     "shell.execute_reply.started": "2025-03-30T08:15:38.827685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans and tokenizes text data using spaCy.\"\"\"\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    # Remove stopwords, punctuation, and lemmatize tokens\n",
    "    tokens = [\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:44.274189Z",
     "iopub.status.busy": "2025-03-30T08:15:44.273858Z",
     "iopub.status.idle": "2025-03-30T08:15:44.278493Z",
     "shell.execute_reply": "2025-03-30T08:15:44.277621Z",
     "shell.execute_reply.started": "2025-03-30T08:15:44.274162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "def extract_features(data, max_features=10000):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    return vectorizer.fit_transform(data), vectorizer\n",
    "    tfidf_matrix = vectorizer.fit_transform(data)\n",
    "    return normalize(tfidf_matrix), vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:47.103939Z",
     "iopub.status.busy": "2025-03-30T08:15:47.103618Z",
     "iopub.status.idle": "2025-03-30T08:15:47.107961Z",
     "shell.execute_reply": "2025-03-30T08:15:47.107154Z",
     "shell.execute_reply.started": "2025-03-30T08:15:47.103914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# kmeans_clustering\n",
    "def kmeans_clustering(features, n_clusters):\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = model.fit_predict(features)\n",
    "    return clusters, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:48.545986Z",
     "iopub.status.busy": "2025-03-30T08:15:48.545652Z",
     "iopub.status.idle": "2025-03-30T08:15:48.550011Z",
     "shell.execute_reply": "2025-03-30T08:15:48.549172Z",
     "shell.execute_reply.started": "2025-03-30T08:15:48.545958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hierarchical_clustering\n",
    "def hierarchical_clustering(features, n_clusters):\n",
    "    model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    clusters = model.fit_predict(features.toarray())\n",
    "    return clusters, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:49.588276Z",
     "iopub.status.busy": "2025-03-30T08:15:49.587989Z",
     "iopub.status.idle": "2025-03-30T08:15:49.592126Z",
     "shell.execute_reply": "2025-03-30T08:15:49.591136Z",
     "shell.execute_reply.started": "2025-03-30T08:15:49.588253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# GMM_clustering\n",
    "def gmm_clustering(features, n_clusters):\n",
    "    model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    clusters = model.fit_predict(features.toarray())\n",
    "    return clusters, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:51.928894Z",
     "iopub.status.busy": "2025-03-30T08:15:51.928560Z",
     "iopub.status.idle": "2025-03-30T08:15:51.932586Z",
     "shell.execute_reply": "2025-03-30T08:15:51.931758Z",
     "shell.execute_reply.started": "2025-03-30T08:15:51.928870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_clustering(features, clusters):\n",
    "    return silhouette_score(features, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### # Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:53.904271Z",
     "iopub.status.busy": "2025-03-30T08:15:53.903878Z",
     "iopub.status.idle": "2025-03-30T08:15:53.911219Z",
     "shell.execute_reply": "2025-03-30T08:15:53.910198Z",
     "shell.execute_reply.started": "2025-03-30T08:15:53.904230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_clusters(features, clusters, method=\"tsne\"):\n",
    "    \"\"\"Visualize clusters using t-SNE or PCA.\"\"\"\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "    elif method == \"pca\":\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported visualization method\")\n",
    "    \n",
    "    reduced_features = reducer.fit_transform(features.toarray())\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=clusters, palette=\"viridis\")\n",
    "    plt.title(f\"Clusters Visualization ({method.upper()})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:05:41.625038Z",
     "iopub.status.busy": "2025-03-30T09:05:41.624683Z",
     "iopub.status.idle": "2025-03-30T09:05:41.629818Z",
     "shell.execute_reply": "2025-03-30T09:05:41.628918Z",
     "shell.execute_reply.started": "2025-03-30T09:05:41.625008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def determine_optimal_clusters(features, max_clusters=15):\n",
    "    \"\"\"Determine the optimal number of clusters using the Elbow Method.\"\"\"\n",
    "    distortions = []\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(features)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, max_clusters + 1), distortions, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T08:15:57.989226Z",
     "iopub.status.busy": "2025-03-30T08:15:57.988926Z",
     "iopub.status.idle": "2025-03-30T08:59:49.211576Z",
     "shell.execute_reply": "2025-03-30T08:59:49.210785Z",
     "shell.execute_reply.started": "2025-03-30T08:15:57.989202Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['talk.religion.misc', 'comp.graphics', 'sci.space']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Silhouette Score: 0.013303799762404984\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    people_wiki_path = \"/kaggle/input/people-data/people_wiki.csv\"\n",
    "\n",
    "    if os.path.exists(people_wiki_path):\n",
    "        people_wiki = pd.read_csv(people_wiki_path)\n",
    "        people_wiki[\"cleaned_text\"] = people_wiki[\"text\"].apply(preprocess_text)\n",
    "    else:\n",
    "        print(\"People Wikipedia Dataset not found!\")\n",
    "\n",
    "    # Load 20 Newsgroups Dataset\n",
    "    categories = [\"talk.religion.misc\", \"comp.graphics\", \"sci.space\"]\n",
    "    print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "    print(categories)\n",
    "    newsgroups = fetch_20newsgroups(subset=\"all\", categories=categories, shuffle=False, remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "    newsgroups_data = pd.DataFrame({\"content\": newsgroups.data})\n",
    "    newsgroups_data[\"cleaned_text\"] = newsgroups_data[\"content\"].apply(preprocess_text)\n",
    "\n",
    "    # Combine datasets for clustering\n",
    "    combined_text = pd.concat([people_wiki[\"cleaned_text\"], newsgroups_data[\"cleaned_text\"]], ignore_index=True)\n",
    "\n",
    "    # Feature extraction\n",
    "    tfidf_features, tfidf_vectorizer = extract_features(combined_text)\n",
    "\n",
    "    # K-Means Clustering\n",
    "    num_clusters = 10  \n",
    "    kmeans_clusters, kmeans_model = kmeans_clustering(tfidf_features, num_clusters)\n",
    "    silhouette_kmeans = evaluate_clustering(tfidf_features, kmeans_clusters)\n",
    "    print(f\"K-Means Silhouette Score: {silhouette_kmeans}\")\n",
    "\n",
    "    # Hierarchical Clustering\n",
    "    hierarchical_clusters, hierarchical_model = hierarchical_clustering(tfidf_features, num_clusters)\n",
    "    silhouette_hierarchical = evaluate_clustering(tfidf_features, hierarchical_clusters)\n",
    "    print(f\"Hierarchical Clustering Silhouette Score: {silhouette_hierarchical}\")\n",
    "\n",
    "    # GMM Clustering\n",
    "    gmm_clusters, gmm_model = gmm_clustering(tfidf_features, num_clusters)\n",
    "    silhouette_gmm = evaluate_clustering(tfidf_features, gmm_clusters)\n",
    "    print(f\"GMM Silhouette Score: {silhouette_gmm}\")\n",
    "\n",
    "    # Visualization\n",
    "    visualize_clusters(tfidf_features, kmeans_clusters, method=\"tsne\")\n",
    "    visualize_clusters(tfidf_features, gmm_clusters, method=\"pca\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6999615,
     "sourceId": 11209684,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7002129,
     "sourceId": 11213548,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
