README for People Wikipedia Dataset
Project Overview
Weâ€™re going to work on an Unsupervised Learning Document Clustering Project, where weâ€™ll apply clustering algorithms to datasets:
ðŸ“Œ People Wikipedia Dataset â€“ Biographical articles with URIs, names, and text from Wikipedia.

This dataset is ideal for analyzing textual content related to biographies and clustering the data into meaningful groups based on content similarity.

ðŸ”¹ Key Tasks
âœ… Data Collection & Preprocessing

Load and clean biographical articles from the dataset to prepare for clustering.

âœ… Feature Extraction (TF-IDF, Word Embeddings)

Convert text into numerical representations for effective clustering using TF-IDF or advanced word embeddings.

âœ… Clustering

Apply clustering algorithms such as K-Means, Hierarchical Clustering, and Gaussian Mixture Models (GMM) to group documents.

âœ… Evaluation

Measure the quality of clustering with metrics like Silhouette Score and Purity Score.

âœ… Visualizations

Visualize the clustering results using dimensionality reduction techniques such as t-SNE, PCA, and dendrograms.

ðŸ“‚ Project Structure
The project is organized into well-structured Python modules and directories:

Data: For raw and preprocessed datasets.

Preprocessing: Scripts for cleaning and feature extraction.

Clustering: Algorithms for document clustering.

Evaluation: Metrics to assess clustering quality.

Visualization: Tools for visualizing results effectively

